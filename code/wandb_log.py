import wandb
import pandas as pd
import os
from tabulate import tabulate

wandb.login()
api = wandb.Api(timeout=60)

# êµ¬ì„±
shots_list = [5, 10]
backbones = ["mlpbp", "spectroresnet", "bptransformer"]
metric_sets = {
    "mae_sum": ("sbp", "dbp"),
    "gal_sum": ("sbp_gal", "dbp_gal"),
}
cache_file = "./wandb_runs.parquet"

# ìºì‹œ ë¶ˆëŸ¬ì˜¤ê¸°
if os.path.exists(cache_file):
    print("ğŸ“¦ Using cached results...")
    df = pd.read_parquet(cache_file)
else:
    print("ğŸ“¡ Fetching results from WandB...")
    rows = []

    for shots in shots_list:
        for backbone in backbones:
            project_name = f"l2p_bp/mqfp_{shots}shot_backbone{backbone}"
            try:
                runs = api.runs(project_name)
            except Exception as e:
                print(f"âŒ Failed to load project {project_name}: {e}")
                continue

            for run in runs:
                transfer = run.config.get("transfer")
                target = run.config.get("target")

                if not transfer or not target:
                    print(f"âš ï¸ Missing transfer/target in run {run.name}, skipping")
                    continue

                for metric_type, (m1, m2) in metric_sets.items():
                    try:
                        val1 = run.summary.get(m1)
                        val2 = run.summary.get(m2)
                        if val1 is not None and val2 is not None:
                            total = val1 + val2
                            rows.append({
                                "shots": shots,
                                "backbone": backbone,
                                "transfer": transfer,
                                "target": target,
                                "metric_type": metric_type,
                                "avg_sum": total
                            })
                    except Exception as e:
                        print(f"âš ï¸ Error in run {run.name}: {e}")

    df = pd.DataFrame(rows)
    df.to_parquet(cache_file)
    print(f"âœ… Saved to cache: {cache_file}")

# ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
def print_multiindex_table(df, shots, metric_type, title):
    df_sub = df[(df["shots"] == shots) & (df["metric_type"] == metric_type)]
    df_grouped = df_sub.groupby(["backbone", "transfer", "target"])["avg_sum"].min().reset_index()
    df_pivot = df_grouped.pivot(index="backbone", columns=["transfer", "target"], values="avg_sum")
    df_pivot = df_pivot.round(4)

    # âœ… ì„±ëŠ¥ ë‚®ì€ ìˆœ ì •ë ¬ (NaN ë¬´ì‹œ)
    df_pivot["avg"] = df_pivot.min(axis=1, skipna=True)
    df_pivot = df_pivot.sort_values(by="avg").drop(columns="avg")

    order = ["mlpbp", "spectroresnet", "bptransformer"]
    df_pivot = df_pivot.reindex(order)      # â˜… ì—¬ê¸° í•œ ì¤„
    
    print(f"\nğŸ“Š {title} (shots={shots}, lower is better):\n")
    print(tabulate(df_pivot, headers="keys", tablefmt="github"))

# ì¶œë ¥
print_multiindex_table(df, 5, "mae_sum", "SBP+DBP MAE Sum")
print_multiindex_table(df, 10, "mae_sum", "SBP+DBP MAE Sum")
print_multiindex_table(df, 5, "gal_sum", "SBP+DBP GAL Sum")
print_multiindex_table(df, 10, "gal_sum", "SBP+DBP GAL Sum")

def print_best_counts(df, shots, metric_type, order):
    df_sub = df[(df["shots"] == shots) & (df["metric_type"] == metric_type)]

    # (1) ê° ì¡°í•©ì˜ ìµœì†Œê°’ë§Œ ë‚¨ê¸´ í”¼ë²—
    pivot = pd.pivot_table(
        df_sub,
        index="backbone",
        columns=["transfer", "target"],
        values="avg_sum",
        aggfunc="min"
    )

    # (2) transfer-target ì—´ë§ˆë‹¤ ì–´ë–¤ backboneì´ ìµœì†Œì¸ê°€?
    best_per_pair = pivot.idxmin()            # Series: col â†’ backbone
    counts = best_per_pair.value_counts().reindex(order, fill_value=0)

    print(f"\nğŸ† Best-count summary  |  metric={metric_type}, shots={shots}")
    for b in order:
        print(f"{b:14}: {counts[b]}")

order = ["mlpbp", "spectroresnet", "bptransformer"]

for s in shots_list:
    for m in metric_sets.keys():
        print_best_counts(df, s, m, order)
