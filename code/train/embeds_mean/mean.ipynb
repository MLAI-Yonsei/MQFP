{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing group means: 100%|██████████| 4/4 [00:00<00:00, 8738.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mean embedding: sensors_mean_embeddings.pt (4, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "ds_tag   = \"sensors\"\n",
    "backbone = \"bptransformer\"\n",
    "N_folds  = 5\n",
    "embed_files = [\n",
    "    f\"/data1/bubble3jh/bp_L2P/code/train/embeds_mean/{backbone}/{ds_tag}_fold{i}_ALL.pt\" for i in range(N_folds)\n",
    "]\n",
    "\n",
    "all_embeddings = []\n",
    "all_groups     = []\n",
    "\n",
    "for f in embed_files:\n",
    "    if not os.path.exists(f):\n",
    "        print(f\"[!] missing: {f}\")\n",
    "        continue\n",
    "\n",
    "    embs = torch.load(f)\n",
    "    all_embeddings.append(embs[\"embeddings\"])       # (N_i, D)\n",
    "    all_groups.append(embs[\"labels\"][:, 0].long())  # SP만 사용해 group 구별했다고 가정한 경우 → 수정 가능\n",
    "\n",
    "embeddings_tensor = torch.cat(all_embeddings, dim=0)  # (N_total, D)\n",
    "groups_tensor     = torch.cat(all_groups, dim=0)      # (N_total,)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. group별 평균 embedding 계산\n",
    "# -----------------------------------------------------\n",
    "groups = groups_tensor.cpu().numpy()                 # int64\n",
    "embeds = embeddings_tensor.cpu().numpy()             # float32\n",
    "\n",
    "mean_embeddings = []\n",
    "for group in tqdm(range(4), desc=\"Computing group means\"):\n",
    "    indices         = np.where(groups == group)[0]\n",
    "    group_embeds    = embeds[indices]\n",
    "    mean_embedding  = np.mean(group_embeds, axis=0)\n",
    "    mean_embeddings.append(mean_embedding)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. 저장\n",
    "# -----------------------------------------------------\n",
    "mean_embeddings_tensor = torch.tensor(mean_embeddings)  # (4, D)\n",
    "torch.save(mean_embeddings_tensor, f\"{backbone}/{ds_tag}_mean_embeddings.pt\")\n",
    "print(f\"Saved mean embedding: {ds_tag}_mean_embeddings.pt {tuple(mean_embeddings_tensor.shape)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
